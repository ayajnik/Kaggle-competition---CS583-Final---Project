{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Updates",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j9uHBQh54L0",
        "colab_type": "text"
      },
      "source": [
        "# **CS -583 Final**\n",
        "# **Project Report**\n",
        "\n",
        "Author -Ayush Yajnik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BZI5Il46jaQ",
        "colab_type": "text"
      },
      "source": [
        "# **Summary**\n",
        "\n",
        "This report is in response to the final project that we had to submit for our course on Deep Learning at Stevens Institute of Technology. For this submission,we had to participate in an active Kaggle Competition and use our skills in Machine Learning and Deep Learning to solve the task given to us in Kaggle.  \n",
        "\n",
        "The competition was posted by Max Plank Institute of Meteorology. In this challenge, we had to build a model to classify cloud organization patterns from satellite images. If successful, we’ll help scientists to better understand how clouds will shape our future climate. This research will guide the development of next-generation models which could reduce uncertainties in climate projections.\n",
        "\n",
        "There are many ways in which clouds can organize, but the boundaries between different forms of organization are murky. This makes it challenging to build traditional rule-based algorithms to separate cloud features. The human eye, however, is really good at detecting features—such as clouds that resemble flowers.\n",
        "\n",
        "The name of the competition is Understanding Clouds from Satellite Images and I was ranked in the top 97% of total participants. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ajk1578f-5g3",
        "colab_type": "text"
      },
      "source": [
        "# **PROBLEM DESCRIPTION**\n",
        "\n",
        "Climate change has been at the top of our minds and on the forefront of important political decision-making for many years. We hope you can use this competition’s dataset to help demystify an important climatic variable. Scientists, like those at Max Planck Institute for Meteorology, are leading the charge with new research on the world’s ever-changing atmosphere and they need your help to better understand the clouds.\n",
        "\n",
        "Shallow clouds play a huge role in determining the Earth's climate. They’re also difficult to understand and to represent in climate models. By classifying different types of cloud organization, researchers at Max Planck hope to improve our physical understanding of these clouds, which in turn will help us build better climate models.\n",
        "\n",
        "There are many ways in which clouds can organize, but the boundaries between different forms of organization are murky. This makes it challenging to build traditional rule-based algorithms to separate cloud features. The human eye, however, is really good at detecting features—such as clouds that resemble flowers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rELLT0zm-_bl",
        "colab_type": "text"
      },
      "source": [
        "# **SOLUTION**\n",
        "\n",
        "The approach towards solving this complex problem was simple and clear. I wanted to make a very comprehensive analysis about the problem before actually implementing the Machine Learning/ Deep Learning Algorithm. Hence, in the description of the competition, we were also given an academic paper as a reference. \n",
        "\n",
        "So, I first analyzed that academic  paper. For this, I used the concepts from Network science like Betweeness Centrality, Degree Centrality and also community detecction algorithm. With the help of this analysis, I was able to understand the theme of not only the academic paper but also the competition that I entered into. I also used an hypothesis(Yajnik-Barabassi Algorithm for Preferrential Attachment) that I formulated which is based on the idea of Albert-Barabassi Model of Preferrential Attachment. I formulated this hypothesis while I was a graduate research assistant at Stevens Institute of Technology. The hypothesis helps in predicting the behavior of data points in accordance to the behvior of data point with the highest value. \n",
        "\n",
        "![alt text](https://www.kaggleusercontent.com/kf/23664981/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..SQmicqMrKcLl8tWLMEJnww.XxBa4g6drCrvTCdIhUnjegaATmhz46RRomEc7o6NxahFT4SvP6sZGIxddkv1lDo8Pvz59WrwboDPd1sAE4Qg7RfCPDcGIUPetzN4YWXjsFKBaioLxfYhhf_mXnWwn7pyEiiYZTXrcznHTMaY0EfJyFGZ_-YmMX-6wpL0zACsCEZ4oX5jwQAH_w1_NfD2L7Yh14Nt1gxeW5ylP6KnOiyM5g.d4xIFdArGVsJNz3EW1digA/__results___files/__results___20_0.png)\n",
        "\n",
        "The following image is from the community detection algorithm and tells us the number of communities that exists in the paper which helps us to classify words and pairs of words.\n",
        "\n",
        "As per the results from the hypothesis that I formulated, it came to my notice that the word \"mcc\" was used heavily by researchers in their paper and hence we can say that there is a high probability that the researchers main theme would revolve around this word only or maybe they are looking to highlight this word as their main theme of their paper.\n",
        "\n",
        "Now we move on to our main data set. Before moving on to our image classification task, I created some basic exploratory data analysis where I found the following results:\n",
        "\n",
        "![alt text](https://www.kaggleusercontent.com/kf/23664981/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..SQmicqMrKcLl8tWLMEJnww.XxBa4g6drCrvTCdIhUnjegaATmhz46RRomEc7o6NxahFT4SvP6sZGIxddkv1lDo8Pvz59WrwboDPd1sAE4Qg7RfCPDcGIUPetzN4YWXjsFKBaioLxfYhhf_mXnWwn7pyEiiYZTXrcznHTMaY0EfJyFGZ_-YmMX-6wpL0zACsCEZ4oX5jwQAH_w1_NfD2L7Yh14Nt1gxeW5ylP6KnOiyM5g.d4xIFdArGVsJNz3EW1digA/__results___files/__results___42_0.png)\n",
        "\n",
        "![alt text](https://www.kaggleusercontent.com/kf/23664981/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..SQmicqMrKcLl8tWLMEJnww.XxBa4g6drCrvTCdIhUnjegaATmhz46RRomEc7o6NxahFT4SvP6sZGIxddkv1lDo8Pvz59WrwboDPd1sAE4Qg7RfCPDcGIUPetzN4YWXjsFKBaioLxfYhhf_mXnWwn7pyEiiYZTXrcznHTMaY0EfJyFGZ_-YmMX-6wpL0zACsCEZ4oX5jwQAH_w1_NfD2L7Yh14Nt1gxeW5ylP6KnOiyM5g.d4xIFdArGVsJNz3EW1digA/__results___files/__results___49_0.png)\n",
        "\n",
        "For image classification, I used third party libraries like OpenCV, Pillow. The core idea behind classification was Image Segmentation. \n",
        "I converted RLE(run length encoding) string to numpy array \n",
        "\n",
        "Parameters: \n",
        "rle_string (str): string of rle encoded mask\n",
        "height (int): height of the mask\n",
        "width (int): width of the mask\n",
        "\n",
        "Returns: \n",
        "numpy.array: numpy array of the mask\n",
        "\n",
        "\n",
        "Then I created a Function to visualize the image and the mask.\n",
        "INPUT:\n",
        "        \n",
        "line_id - id of the line to visualize the masks\n",
        "shape - image shape\n",
        "RETURNS:\n",
        "        \n",
        "np_mask - numpy segmentation map\n",
        "\n",
        "Then  I created a Function to visualize several segmentation maps.\n",
        "INPUT:\n",
        "\n",
        "image_id - filename of the image\n",
        "\n",
        "RETURNS:\n",
        "\n",
        "np_mask - numpy segmentation map\n",
        "\n",
        "Then I created a Function to visualize several segmentation maps.\n",
        "INPUT:\n",
        "\n",
        "image_id - filename of the image\n",
        "\n",
        "RETURNS:\n",
        "\n",
        "np_mask - numpy segmentation map\n",
        "\n",
        "The results from the classification is as follows:\n",
        "\n",
        "![alt text](https://www.kaggleusercontent.com/kf/23664981/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..SQmicqMrKcLl8tWLMEJnww.XxBa4g6drCrvTCdIhUnjegaATmhz46RRomEc7o6NxahFT4SvP6sZGIxddkv1lDo8Pvz59WrwboDPd1sAE4Qg7RfCPDcGIUPetzN4YWXjsFKBaioLxfYhhf_mXnWwn7pyEiiYZTXrcznHTMaY0EfJyFGZ_-YmMX-6wpL0zACsCEZ4oX5jwQAH_w1_NfD2L7Yh14Nt1gxeW5ylP6KnOiyM5g.d4xIFdArGVsJNz3EW1digA/__results___files/__results___85_0.png)\n",
        "\n",
        "![alt text](https://www.kaggleusercontent.com/kf/23664981/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..SQmicqMrKcLl8tWLMEJnww.XxBa4g6drCrvTCdIhUnjegaATmhz46RRomEc7o6NxahFT4SvP6sZGIxddkv1lDo8Pvz59WrwboDPd1sAE4Qg7RfCPDcGIUPetzN4YWXjsFKBaioLxfYhhf_mXnWwn7pyEiiYZTXrcznHTMaY0EfJyFGZ_-YmMX-6wpL0zACsCEZ4oX5jwQAH_w1_NfD2L7Yh14Nt1gxeW5ylP6KnOiyM5g.d4xIFdArGVsJNz3EW1digA/__results___files/__results___91_0.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFMTpK9hIprf",
        "colab_type": "text"
      },
      "source": [
        "# **CREDITS AND REFERENCES**\n",
        "\n",
        "Article on Medium from competition organizers.\n",
        "\n",
        "\n",
        "\n",
        "Original paper for the competition.\n",
        "\n",
        "\n",
        "\n",
        "EDA: Find Me In The Clouds kernel. I took rle_to_mask function from there.\n",
        "\n",
        "\n",
        "My kernel on data augmentation packages for those who want to learn more about \n",
        "different data augmantation packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUtR1WhHJlh2",
        "colab_type": "text"
      },
      "source": [
        "# **UPDATES**\n",
        "\n",
        "Added the analysis of mask area distribution for each label.\n",
        "\n",
        "\n",
        "\n",
        "Added the analysis for number of masks per image for each label.\n",
        "\n",
        "\n",
        "\n",
        "Corrected issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpYycpCVKI42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}